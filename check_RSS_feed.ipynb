{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c9b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES = {\n",
    "    \"economic_times\": {\n",
    "        \"rss\": \"https://economictimes.indiatimes.com/rssfeedstopstories.cms\",\n",
    "        \"categories\": [\"Business\", \"Technology\"]\n",
    "    },\n",
    "    \"times_of_india\": {\n",
    "        \"rss\": \"https://timesofindia.indiatimes.com/rssfeedstopstories.cms\",\n",
    "        \"categories\": [\"General News\", \"Business\"] \n",
    "    },\n",
    "    \"techcrunch\": {\n",
    "        \"rss\": \"https://techcrunch.com/feed/\",\n",
    "        \"categories\": [\"Technology\", \"Startups\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8af512",
   "metadata": {},
   "source": [
    "# News Article Processing Pipeline\n",
    "\n",
    "This notebook implements a pipeline for:\n",
    "1. Fetching news articles from multiple RSS feeds\n",
    "2. Extracting full article content\n",
    "3. Generating article summaries using LLM\n",
    "4. Detecting and removing duplicate articles\n",
    "\n",
    "## Components\n",
    "- RSS Feed Processing: feedparser\n",
    "- Content Extraction: newspaper3k\n",
    "- Summarization: OpenAI/Grok via OpenRouter\n",
    "- Deduplication: TF-IDF with cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df89bcd",
   "metadata": {},
   "source": [
    "# 1. Configuration and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c742d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import feedparser\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Content extraction\n",
    "from newspaper import Article\n",
    "\n",
    "# ML/NLP imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Environment and API configuration\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI client with Openrouter\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"https://github.com/ajay-manwani/news_extraction\",\n",
    "        \"X-Title\": \"News Extraction Project\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030a2f7",
   "metadata": {},
   "source": [
    "# 2. News Sources Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed82a55",
   "metadata": {},
   "source": [
    "# News Article Processing Pipeline\n",
    "\n",
    "This notebook implements a pipeline for:\n",
    "1. Fetching news articles from multiple RSS feeds\n",
    "2. Extracting full article content\n",
    "3. Generating article summaries using LLM\n",
    "4. Detecting and removing duplicate articles\n",
    "\n",
    "The pipeline uses:\n",
    "- feedparser for RSS feed processing\n",
    "- newspaper3k for article content extraction\n",
    "- OpenAI/Grok for article summarization\n",
    "- TF-IDF and cosine similarity for deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e23b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI client with Openrouter\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"https://github.com/ajay-manwani/news_extraction\",\n",
    "        \"X-Title\": \"News Extraction Project\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4b409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(text, max_tokens=300):\n",
    "    \"\"\"\n",
    "    Summarize article text using x-ai/grok-4-fast model via Openrouter\n",
    "    \n",
    "    Args:\n",
    "        text (str): The article text to summarize\n",
    "        max_tokens (int): Maximum length of the summary\n",
    "        \n",
    "    Returns:\n",
    "        str: Summarized text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct the prompt\n",
    "        prompt = f\"\"\"Please provide a concise summary of the following article. \n",
    "        Focus on the main points and key information:\n",
    "\n",
    "        {text}\n",
    "\n",
    "        Summary:\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"x-ai/grok-4-fast:free\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            #max_tokens=max_tokens\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in summarization: {str(e)}\")\n",
    "        return \"Error generating summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529872f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "519c5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_rss_feed(source_name, source_info):\n",
    "    \"\"\"\n",
    "    Fetch and parse RSS feed from a given source\n",
    "    \n",
    "    Args:\n",
    "        source_name (str): Name of the source\n",
    "        source_info (dict): Dictionary containing RSS feed URL and categories\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing parsed news items\n",
    "    \"\"\"\n",
    "    feed = feedparser.parse(source_info['rss'])\n",
    "    \n",
    "    news_items = []\n",
    "    for entry in feed.entries:\n",
    "        news_item = {\n",
    "            'source': source_name,\n",
    "            'title': entry.get('title', ''),\n",
    "            'link': entry.get('link', ''),\n",
    "            'published': entry.get('published', ''),\n",
    "            'summary': entry.get('summary', ''),\n",
    "            'categories': source_info['categories']\n",
    "        }\n",
    "        news_items.append(news_item)\n",
    "    \n",
    "    return news_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb1db0",
   "metadata": {},
   "source": [
    "# Test Article Summarization\n",
    "Let's test our summarization function on a sample article and compare the original text with the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66eedbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>times_of_india</td>\n",
       "      <td>'GST Bachat Utsav': PM Modi writes open letter...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/gst-...</td>\n",
       "      <td>Mon, 22 Sep 2025 17:10:45 +0530</td>\n",
       "      <td>Prime Minister Modi announced the 'GST Bachat ...</td>\n",
       "      <td>[General News, Business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>times_of_india</td>\n",
       "      <td>Appointed, ignored &amp; unpaid: Meet India's 'inv...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/appo...</td>\n",
       "      <td>Mon, 22 Sep 2025 01:02:13 +0530</td>\n",
       "      <td>Across India, tens of thousands of teachers wo...</td>\n",
       "      <td>[General News, Business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>times_of_india</td>\n",
       "      <td>'Main bhi Bharat hoon': Rajnath Singh says 'Po...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/main...</td>\n",
       "      <td>Mon, 22 Sep 2025 15:29:01 +0530</td>\n",
       "      <td>Defence Minister Rajnath Singh addressed the I...</td>\n",
       "      <td>[General News, Business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>times_of_india</td>\n",
       "      <td>Did Pak bomb a Khyber Pakhtunkhwa village and ...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/world/paki...</td>\n",
       "      <td>Mon, 22 Sep 2025 14:27:06 +0530</td>\n",
       "      <td></td>\n",
       "      <td>[General News, Business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>times_of_india</td>\n",
       "      <td>Why are Pakistan players avoiding Indian media?</td>\n",
       "      <td>https://timesofindia.indiatimes.com/sports/cri...</td>\n",
       "      <td>Mon, 22 Sep 2025 16:59:46 +0530</td>\n",
       "      <td>Pakistan cricket faces criticism for on-field ...</td>\n",
       "      <td>[General News, Business]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                              title  \\\n",
       "0  times_of_india  'GST Bachat Utsav': PM Modi writes open letter...   \n",
       "1  times_of_india  Appointed, ignored & unpaid: Meet India's 'inv...   \n",
       "2  times_of_india  'Main bhi Bharat hoon': Rajnath Singh says 'Po...   \n",
       "3  times_of_india  Did Pak bomb a Khyber Pakhtunkhwa village and ...   \n",
       "4  times_of_india    Why are Pakistan players avoiding Indian media?   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://timesofindia.indiatimes.com/india/gst-...   \n",
       "1  https://timesofindia.indiatimes.com/india/appo...   \n",
       "2  https://timesofindia.indiatimes.com/india/main...   \n",
       "3  https://timesofindia.indiatimes.com/world/paki...   \n",
       "4  https://timesofindia.indiatimes.com/sports/cri...   \n",
       "\n",
       "                         published  \\\n",
       "0  Mon, 22 Sep 2025 17:10:45 +0530   \n",
       "1  Mon, 22 Sep 2025 01:02:13 +0530   \n",
       "2  Mon, 22 Sep 2025 15:29:01 +0530   \n",
       "3  Mon, 22 Sep 2025 14:27:06 +0530   \n",
       "4  Mon, 22 Sep 2025 16:59:46 +0530   \n",
       "\n",
       "                                             summary                categories  \n",
       "0  Prime Minister Modi announced the 'GST Bachat ...  [General News, Business]  \n",
       "1  Across India, tens of thousands of teachers wo...  [General News, Business]  \n",
       "2  Defence Minister Rajnath Singh addressed the I...  [General News, Business]  \n",
       "3                                                     [General News, Business]  \n",
       "4  Pakistan cricket faces criticism for on-field ...  [General News, Business]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test with one source first\n",
    "source_name =  \"times_of_india\" #\"economic_times\" #\"techcrunch\"\n",
    "news_items = fetch_rss_feed(source_name, SOURCES[source_name])\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "df = pd.DataFrame(news_items)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e59578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import time\n",
    "\n",
    "def extract_article_content(url):\n",
    "    \"\"\"\n",
    "    Extract article content using newspaper3k\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL of the article\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing article details\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add a small delay to be respectful to the servers\n",
    "        time.sleep(1)\n",
    "        \n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        \n",
    "        return {\n",
    "            'full_text': article.text,\n",
    "            'authors': article.authors,\n",
    "            'top_image': article.top_image,\n",
    "            'article_date': article.publish_date\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {str(e)}\")\n",
    "        return {\n",
    "            'full_text': '',\n",
    "            'authors': [],\n",
    "            'top_image': '',\n",
    "            'article_date': None\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26adc9",
   "metadata": {},
   "source": [
    "# Test Article Extraction\n",
    "Let's try our enhanced news fetching with article content extraction. We'll start with a small sample to make sure everything works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "922ba8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles processed: 3\n",
      "\n",
      "Columns available: ['source', 'title', 'link', 'published', 'summary', 'categories', 'full_text', 'authors', 'top_image', 'article_date']\n",
      "\n",
      "Sample article details:\n",
      "\n",
      "Article 1:\n",
      "Title: Commonwealth Fusion Systems books a $1B+ power deal for its future fusion reactor\n",
      "Authors: ['Tim De Chant', 'Senior Reporter', 'Karyne Levy', 'Connie Loizos', 'Sarah Perez', 'Julie Bort', 'Maxwell Zeff', 'Ivan Mehta', '--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var', 'Media']\n",
      "Text length: 4535 characters\n",
      "--------------------------------------------------\n",
      "\n",
      "Article 2:\n",
      "Title: Powered by India’s small businesses, UK fintech Tide becomes a TPG-backed unicorn\n",
      "Authors: ['Jagmeet Singh', 'Karyne Levy', 'Connie Loizos', 'Sarah Perez', 'Julie Bort', 'Maxwell Zeff', 'Ivan Mehta', '--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var', 'Media', 'Min-Width']\n",
      "Text length: 4837 characters\n",
      "--------------------------------------------------\n",
      "\n",
      "Article 3:\n",
      "Title: VCs are still hiring MBAs, but firms are starting to need other experience more\n",
      "Authors: ['Connie Loizos', 'Techcrunch Events', 'Dominic-Madori Davis', '.Post-Authors-List__Authors --Font-Size Var', 'Align-Items Center Display Flex Gap Var', '.Post-Authors-List__Authors .Post-Authors-List__Author-Thumbs Display Flex Flex-Shrink Margin Padding .Post-Authors-List__Authors .Post-Authors-List__Author-Thumbs Li List-Style None Margin-Left Margin-Top Important .Post-Authors-List__Authors .Post-Authors-List__Author-Thumbs Li First-Child Margin-Left .Post-Authors-List__Authors .Post-Authors-List__Author-Thumbs .Post-Authors-List__Author-Thumb Background-Color Var', 'Border Solid Var --Wp--Custom--Color--White', 'Border-Radius', 'Height -O-Object-Fit Cover Object-Fit Cover Width .Post-Authors-List__Authors .Post-Authors-List__Author-List Display Flex Flex-Wrap Wrap Gap Var', 'List-Style-Type None Margin-Bottom Margin-Top Padding .Post-Authors-List__Authors .Post-Authors-List__Author-List Li List-Style None Margin-Top .Post-Authors-List__Authors .Post-Authors-List__Author-List Li Not']\n",
      "Text length: 1268 characters\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with a few articles from one source\n",
    "source_name = \"techcrunch\"  # TechCrunch tends to have more consistent article structure\n",
    "news_items = fetch_rss_feed(source_name, SOURCES[source_name])\n",
    "\n",
    "# Take first 3 articles for testing\n",
    "sample_news = news_items[:3]\n",
    "\n",
    "# Add article content\n",
    "for item in sample_news:\n",
    "    article_content = extract_article_content(item['link'])\n",
    "    item.update(article_content)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_with_content = pd.DataFrame(sample_news)\n",
    "\n",
    "# Display results\n",
    "print(\"Number of articles processed:\", len(df_with_content))\n",
    "print(\"\\nColumns available:\", df_with_content.columns.tolist())\n",
    "print(\"\\nSample article details:\")\n",
    "for idx, row in df_with_content.iterrows():\n",
    "    print(f\"\\nArticle {idx + 1}:\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Authors: {row['authors']}\")\n",
    "    print(f\"Text length: {len(row['full_text'])} characters\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "334b1224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>categories</th>\n",
       "      <th>full_text</th>\n",
       "      <th>authors</th>\n",
       "      <th>top_image</th>\n",
       "      <th>article_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>techcrunch</td>\n",
       "      <td>Commonwealth Fusion Systems books a $1B+ power...</td>\n",
       "      <td>https://techcrunch.com/2025/09/22/commonwealth...</td>\n",
       "      <td>Mon, 22 Sep 2025 11:00:00 +0000</td>\n",
       "      <td>The fusion startup has inked a deal with Itali...</td>\n",
       "      <td>[Technology, Startups]</td>\n",
       "      <td>Commonwealth Fusion Systems has agreed to sell...</td>\n",
       "      <td>[Tim De Chant, Senior Reporter, Karyne Levy, C...</td>\n",
       "      <td>https://techcrunch.com/wp-content/uploads/2025...</td>\n",
       "      <td>2025-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>techcrunch</td>\n",
       "      <td>Powered by India’s small businesses, UK fintec...</td>\n",
       "      <td>https://techcrunch.com/2025/09/21/powered-by-i...</td>\n",
       "      <td>Mon, 22 Sep 2025 06:00:00 +0000</td>\n",
       "      <td>Tide serves over 1.6 million micro and small e...</td>\n",
       "      <td>[Technology, Startups]</td>\n",
       "      <td>U.K.-based fintech Tide has entered the unicor...</td>\n",
       "      <td>[Jagmeet Singh, Karyne Levy, Connie Loizos, Sa...</td>\n",
       "      <td>https://techcrunch.com/wp-content/uploads/2025...</td>\n",
       "      <td>2025-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>techcrunch</td>\n",
       "      <td>VCs are still hiring MBAs, but firms are start...</td>\n",
       "      <td>https://techcrunch.com/2025/09/21/vcs-are-stil...</td>\n",
       "      <td>Sun, 21 Sep 2025 22:23:40 +0000</td>\n",
       "      <td>The MBA-to-VC pipeline remains a very real thi...</td>\n",
       "      <td>[Technology, Startups]</td>\n",
       "      <td>In Brief\\n\\nThe MBA-to-VC pipeline remains a v...</td>\n",
       "      <td>[Connie Loizos, Techcrunch Events, Dominic-Mad...</td>\n",
       "      <td>https://techcrunch.com/wp-content/uploads/2015...</td>\n",
       "      <td>2025-09-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                              title  \\\n",
       "0  techcrunch  Commonwealth Fusion Systems books a $1B+ power...   \n",
       "1  techcrunch  Powered by India’s small businesses, UK fintec...   \n",
       "2  techcrunch  VCs are still hiring MBAs, but firms are start...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://techcrunch.com/2025/09/22/commonwealth...   \n",
       "1  https://techcrunch.com/2025/09/21/powered-by-i...   \n",
       "2  https://techcrunch.com/2025/09/21/vcs-are-stil...   \n",
       "\n",
       "                         published  \\\n",
       "0  Mon, 22 Sep 2025 11:00:00 +0000   \n",
       "1  Mon, 22 Sep 2025 06:00:00 +0000   \n",
       "2  Sun, 21 Sep 2025 22:23:40 +0000   \n",
       "\n",
       "                                             summary              categories  \\\n",
       "0  The fusion startup has inked a deal with Itali...  [Technology, Startups]   \n",
       "1  Tide serves over 1.6 million micro and small e...  [Technology, Startups]   \n",
       "2  The MBA-to-VC pipeline remains a very real thi...  [Technology, Startups]   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Commonwealth Fusion Systems has agreed to sell...   \n",
       "1  U.K.-based fintech Tide has entered the unicor...   \n",
       "2  In Brief\\n\\nThe MBA-to-VC pipeline remains a v...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [Tim De Chant, Senior Reporter, Karyne Levy, C...   \n",
       "1  [Jagmeet Singh, Karyne Levy, Connie Loizos, Sa...   \n",
       "2  [Connie Loizos, Techcrunch Events, Dominic-Mad...   \n",
       "\n",
       "                                           top_image article_date  \n",
       "0  https://techcrunch.com/wp-content/uploads/2025...   2025-09-22  \n",
       "1  https://techcrunch.com/wp-content/uploads/2025...   2025-09-21  \n",
       "2  https://techcrunch.com/wp-content/uploads/2015...   2025-09-21  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5732f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_duplicates(articles_df, text_column='full_text', title_column='title', \n",
    "                   similarity_threshold=0.85):\n",
    "    \"\"\"\n",
    "    Find duplicate articles using TF-IDF and cosine similarity\n",
    "    \n",
    "    Args:\n",
    "        articles_df (pd.DataFrame): DataFrame containing articles\n",
    "        text_column (str): Name of the column containing article text\n",
    "        title_column (str): Name of the column containing article titles\n",
    "        similarity_threshold (float): Threshold for considering articles as duplicates\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicate information\n",
    "    \"\"\"\n",
    "    # Create TF-IDF vectors for the articles\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    \n",
    "    # Combine title and text with more weight on title\n",
    "    combined_text = articles_df[title_column].str.lower() + \" \" + \\\n",
    "                   articles_df[title_column].str.lower() + \" \" + \\\n",
    "                   articles_df[text_column].str.lower()\n",
    "    \n",
    "    # Get TF-IDF matrix\n",
    "    tfidf_matrix = tfidf.fit_transform(combined_text)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Find duplicates\n",
    "    duplicates = []\n",
    "    for i in range(len(articles_df)):\n",
    "        for j in range(i + 1, len(articles_df)):\n",
    "            if cosine_sim[i][j] > similarity_threshold:\n",
    "                duplicates.append({\n",
    "                    'article1_idx': i,\n",
    "                    'article2_idx': j,\n",
    "                    'similarity_score': cosine_sim[i][j],\n",
    "                    'article1_title': articles_df.iloc[i][title_column],\n",
    "                    'article2_title': articles_df.iloc[j][title_column]\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8050c6",
   "metadata": {},
   "source": [
    "# Batch Summarization and Meta-Summary Generation\n",
    "Let's add functionality to:\n",
    "1. Generate summaries for all articles\n",
    "2. Create a meta-summary combining key points from all articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article_summaries(articles_df):\n",
    "    \"\"\"\n",
    "    Generate summaries for all articles in the DataFrame\n",
    "    \n",
    "    Args:\n",
    "        articles_df (pd.DataFrame): DataFrame containing articles with 'full_text' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'summary' column\n",
    "    \"\"\"\n",
    "    print(\"Generating summaries for all articles...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = articles_df.copy()\n",
    "    \n",
    "    # Generate summaries\n",
    "    summaries = []\n",
    "    for idx, row in df.iterrows():\n",
    "        print(f\"Processing article {idx + 1}/{len(df)}\")\n",
    "        summary = summarize_article(row['full_text'])\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    # Add summaries to DataFrame\n",
    "    df['summary'] = summaries\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_meta_summary(articles_df, summary_column='summary'):\n",
    "    \"\"\"\n",
    "    Generate a meta-summary of all article summaries\n",
    "    \n",
    "    Args:\n",
    "        articles_df (pd.DataFrame): DataFrame containing articles with summaries\n",
    "        summary_column (str): Name of the column containing summaries\n",
    "        \n",
    "    Returns:\n",
    "        str: Meta-summary text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Combine all summaries\n",
    "        all_summaries = \"\\n\\n\".join(articles_df[summary_column].tolist())\n",
    "        \n",
    "        # Create prompt for meta-summary\n",
    "        prompt = f\"\"\"Below are summaries of multiple news articles. \n",
    "        Please create a comprehensive meta-summary that:\n",
    "        1. Identifies major themes and trends\n",
    "        2. Highlights key developments across articles\n",
    "        3. Notes any contrasting viewpoints or developments\n",
    "        4. Provides a high-level overview of the news landscape\n",
    "\n",
    "        Article Summaries:\n",
    "        {all_summaries}\n",
    "\n",
    "        Meta-Summary:\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"x-ai/grok-4-fast:free\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=500  # Longer for meta-summary\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating meta-summary: {str(e)}\")\n",
    "        return \"Error generating meta-summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch summarization and meta-summary\n",
    "if len(df_all) > 0:\n",
    "    # Process all articles to get summaries\n",
    "    df_with_summaries = process_article_summaries(df_all)\n",
    "    \n",
    "    # Display some sample summaries\n",
    "    print(\"\\nSample Article Summaries:\")\n",
    "    for idx, row in df_with_summaries.head(2).iterrows():\n",
    "        print(f\"\\nArticle {idx + 1}:\")\n",
    "        print(f\"Title: {row['title']}\")\n",
    "        print(f\"Summary length: {len(row['summary'])} characters\")\n",
    "        print(\"-\" * 80)\n",
    "        print(row['summary'])\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Generate and display meta-summary\n",
    "    print(\"\\nGenerating meta-summary...\")\n",
    "    meta_summary = generate_meta_summary(df_with_summaries)\n",
    "    \n",
    "    print(\"\\nMeta-Summary of All Articles:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(meta_summary)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Add summaries to our main DataFrame\n",
    "    df_all = df_with_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb5b5c",
   "metadata": {},
   "source": [
    "# Test Deduplication\n",
    "Let's test our deduplication function with articles from multiple sources. We'll:\n",
    "1. Fetch articles from different sources\n",
    "2. Extract their content\n",
    "3. Run the deduplication algorithm\n",
    "4. Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05291e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching articles from economic_times...\n",
      "Fetching articles from times_of_india...\n",
      "Fetching articles from times_of_india...\n",
      "Fetching articles from techcrunch...\n",
      "Fetching articles from techcrunch...\n",
      "\n",
      "Checking for duplicates...\n",
      "\n",
      "Found 0 potential duplicate pairs:\n",
      "\n",
      "Checking for duplicates...\n",
      "\n",
      "Found 0 potential duplicate pairs:\n"
     ]
    }
   ],
   "source": [
    "# Fetch articles from multiple sources\n",
    "all_articles = []\n",
    "\n",
    "# Get articles from each source\n",
    "for source_name, source_info in SOURCES.items():\n",
    "    print(f\"Fetching articles from {source_name}...\")\n",
    "    \n",
    "    # Get RSS feed items\n",
    "    news_items = fetch_rss_feed(source_name, source_info)\n",
    "    \n",
    "    # Take first 5 articles from each source\n",
    "    for item in news_items[:5]:\n",
    "        # Extract full content\n",
    "        article_content = extract_article_content(item['link'])\n",
    "        item.update(article_content)\n",
    "        all_articles.append(item)\n",
    "\n",
    "# Create DataFrame with all articles\n",
    "df_all = pd.DataFrame(all_articles)\n",
    "\n",
    "# Find duplicates\n",
    "print(\"\\nChecking for duplicates...\")\n",
    "duplicates_df = find_duplicates(df_all)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nFound {len(duplicates_df)} potential duplicate pairs:\")\n",
    "if not duplicates_df.empty:\n",
    "    for _, row in duplicates_df.iterrows():\n",
    "        print(f\"\\nSimilarity Score: {row['similarity_score']:.3f}\")\n",
    "        print(f\"Article 1: {row['article1_title']}\")\n",
    "        print(f\"Article 2: {row['article2_title']}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ae4e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article:\n",
      "Title: Commonwealth Fusion Systems books a $1B+ power deal for its future fusion reactor\n",
      "Length: 4535 characters\n",
      "--------------------------------------------------------------------------------\n",
      "Commonwealth Fusion Systems has agreed to sell Italian energy company Eni more than $1 billion worth of power from its first fusion reactor.\n",
      "\n",
      "The power plant will be built outside of Richmond, Virginia, close to some of the highest densities of data centers in the country. The 400-megawatt fusion reactor, called Arc, is expected to open in the early 2030s, CEO Bob Mumgaard said.\n",
      "\n",
      "The Eni agreement is the second such deal for Commonwealth Fusion Systems (CFS). In June, Google said that it would b ...\n",
      "\n",
      "\n",
      "Generating summary...\n",
      "\n",
      "Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "### Summary of the Article\n",
      "\n",
      "Commonwealth Fusion Systems (CFS), a leading fusion energy company, has signed a deal to sell Italian energy giant Eni over $1 billion worth of electricity from its first commercial fusion reactor, Arc—a 400-megawatt tokamak-based plant using superconducting magnets to generate power from plasma fusion. The reactor will be built near Richmond, Virginia, adjacent to high-density data centers, with operations slated for the early 2030s.\n",
      "\n",
      "This marks CFS's second major power purchase agreement; in June, Google committed to buying half of Arc's output, likely for its data centers. Neither deal discloses specific power volumes or timelines, but the agreements are designed to be flexible, acknowledging the risks of pioneering technology, with no punitive measures for delays.\n",
      "\n",
      "CFS's demonstration reactor, Sparc, in Devens, Massachusetts, is 65% complete and on track to activate in late 2026, providing critical experience for scaling to Arc. Sparc aims to produce net-positive energy, though success is unproven. The company has raised nearly $3 billion in funding, including a recent $863 million round from investors like Nvidia, Google, Breakthrough Energy Ventures, and Eni.\n",
      "\n",
      "Eni, lacking major U.S. operations, plans to resell Arc's power to the grid, potentially at a loss due to high initial costs. The deal primarily secures pricing certainty and attracts project financing, helping establish the market for fusion energy rather than immediate profit.\n",
      "\n",
      "Summary length: 1492 characters\n",
      "\n",
      "Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "### Summary of the Article\n",
      "\n",
      "Commonwealth Fusion Systems (CFS), a leading fusion energy company, has signed a deal to sell Italian energy giant Eni over $1 billion worth of electricity from its first commercial fusion reactor, Arc—a 400-megawatt tokamak-based plant using superconducting magnets to generate power from plasma fusion. The reactor will be built near Richmond, Virginia, adjacent to high-density data centers, with operations slated for the early 2030s.\n",
      "\n",
      "This marks CFS's second major power purchase agreement; in June, Google committed to buying half of Arc's output, likely for its data centers. Neither deal discloses specific power volumes or timelines, but the agreements are designed to be flexible, acknowledging the risks of pioneering technology, with no punitive measures for delays.\n",
      "\n",
      "CFS's demonstration reactor, Sparc, in Devens, Massachusetts, is 65% complete and on track to activate in late 2026, providing critical experience for scaling to Arc. Sparc aims to produce net-positive energy, though success is unproven. The company has raised nearly $3 billion in funding, including a recent $863 million round from investors like Nvidia, Google, Breakthrough Energy Ventures, and Eni.\n",
      "\n",
      "Eni, lacking major U.S. operations, plans to resell Arc's power to the grid, potentially at a loss due to high initial costs. The deal primarily secures pricing certainty and attracts project financing, helping establish the market for fusion energy rather than immediate profit.\n",
      "\n",
      "Summary length: 1492 characters\n"
     ]
    }
   ],
   "source": [
    "# Test summarization with a sample article\n",
    "if len(df_with_content) > 0:\n",
    "    # Take the first article as a test\n",
    "    sample_article = df_with_content.iloc[0]\n",
    "    \n",
    "    print(\"Original Article:\")\n",
    "    print(\"Title:\", sample_article['title'])\n",
    "    print(\"Length:\", len(sample_article['full_text']), \"characters\")\n",
    "    print(\"-\" * 80)\n",
    "    print(sample_article['full_text'][:500], \"...\\n\")  # Show first 500 characters\n",
    "    \n",
    "    # Generate summary\n",
    "    print(\"\\nGenerating summary...\")\n",
    "    summary = summarize_article(sample_article['full_text'])\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(summary)\n",
    "    print(\"\\nSummary length:\", len(summary), \"characters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-extraction (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
